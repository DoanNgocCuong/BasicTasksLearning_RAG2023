{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viết 1 cái mail ngắn Proposal: \n",
    "\n",
    "- Rag strategy . \n",
    "- research: Chunking strategy  \n",
    "\n",
    "Chiến lược Chunking\tMô tả\tƯu điểm\tNhược điểm\tĐộ phù hợp với dataset hiện tại\n",
    "A. Fixed-size Chunking\tChia văn bản thành các đoạn có độ dài cố định với độ overlap.\tDễ triển khai, các chunk có độ dài đồng đều.\tDễ cắt ngang câu và đoạn văn, có thể làm mất ngữ cảnh quan trọng.\tTrung bình\n",
    "B. Chunking Theo Câu\tChia văn bản dựa trên các câu hoàn chỉnh, giữ nguyên ngữ cảnh.\tBảo toàn ngữ cảnh, phù hợp với nội dung có cấu trúc phức tạp.\tCác chunk có độ dài không đồng đều, có thể dẫn đến chunk quá dài.\tCao\n",
    "E. Tách Đệ Quy Ký Tự\tChia nhỏ đệ quy dựa trên các dấu phân cách như dấu chấm câu.\tGiữ cấu trúc tốt hơn tách ký tự đơn giản, phù hợp cho văn bản có cấu trúc rõ ràng.\tCó thể cắt ngang ý nghĩa nếu dấu phân cách không hợp lý.\tTrung bình\n",
    "I. Tách Theo Loại Tài Liệu\tPhân tách dựa trên loại tài liệu (PDF, Markdown, Python code).\tTối ưu cho các loại tài liệu cụ thể, giúp bảo toàn ngữ nghĩa.\tCần phân loại tài liệu trước khi chia nhỏ.\tTrung bình - Cao\n",
    "C. Chunking Kết Hợp (Hybrid)\tKết hợp giữa Fixed-size và Sentence-based, ưu tiên chia tại dấu câu.\tGiữ ngữ cảnh tốt hơn fixed-size, độ dài chunk ổn định hơn sentence-based.\tPhức tạp hơn để triển khai.\tRất cao\n",
    "D. Chunk theo Ngữ Nghĩa\tSử dụng mô hình ngôn ngữ để chia các đoạn theo ngữ nghĩa thay vì chiều dài cố định.\tTối ưu cho tìm kiếm ngữ nghĩa, bảo toàn ý nghĩa tốt nhất.\tYêu cầu tài nguyên tính toán lớn, khó triển khai.\tCao\n",
    "F. Agentic Chunker (Tách Dùng Agent)\tSử dụng các \"agent\" để tự động nhóm các propositions liên quan thành chunks dựa trên ngữ nghĩa.\tTự động tối ưu theo ngữ cảnh, linh hoạt và thông minh hơn.\tPhức tạp, đòi hỏi mô hình AI nâng cao.\tCao\n",
    "\n",
    "\n",
    "\n",
    "- Indexing : research HNSW\n",
    "=========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subject:** Report Processing and get recommend from professor for RAG Strategy and Research on Chunking & Indexing Methods  \n",
    "\n",
    "Dear [Recipient's Name],  \n",
    "\n",
    "I am writing to present a processing my work for resera proposal for a r RAG Strategy and Research on Chunking & Indexing Methods  \n",
    "\n",
    "### **1. Summary Định hướng reserch RAG**  \n",
    "Bản báo cáo tiến trình RAG: tÔI ĐANG NGHIÊN CỨU CÁC METHOD CHO ,,,...\n",
    "CẢM ƠN GIÁO SƯ spending time to review my processing and reviewing my work.\n",
    "### **2. Research: Chunking Strategies**  \n",
    "We have analyzed various chunking strategies to determine their applicability to our current dataset. Below is a summarized evaluation:  \n",
    "- **Hybrid Chunking:** Combines fixed-size and sentence-based methods for optimal context retention. \n",
    "- **Semantic Chunking:** Uses language models for meaning-preserving chunking. \n",
    "- **Hybrid Chunking combine Semantic Chunking**: Combines both fixed-size and semantic chunking. Về mặt lý thuyết thì cách này hiệu năng sẽ tốt hơn 2 cách trước. Tôi sẽ tiến hành implement trên tập dataset thực tế để xem kết quả. \n",
    "- RAPTOR RAG: 1 chiến lược chunking kết hợp với Phân cụm và Summary cụm. Tôi đang nghiên cứu chiến lược này ở đây: https://github.com/parthsarthi03/raptor - đi kèm với bài báo này: arxiv.org/abs/2401.18059\n",
    "- Ngoài ra tôi sẽ research thêm về các chiến lược chunking khác. RẤT MONG NHẬN ĐƯỢC ĐỀ XUẤT, GỢI Ý TỪ GIÁO SƯ VỀ NHỮNG CHIẾN LƯỢC CHUNKING HIỆN ĐẠI VÀ HIỆU QUẢ. \n",
    "\n",
    "### **3. Indexing: HNSW**  \n",
    "- Tôi đang nhắm đến phương pháp Indexing này. \n",
    "- Hiện nay có thể có thêm các method Indexing other , suitable for RAG task. rất mong được professor recommend for me. \n",
    "\n",
    "\n",
    "Best regards,  \n",
    "[Your Name]  \n",
    "[Your Position]  \n",
    "[Your Contact Information]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject: RAG Strategy on Chunking & Indexing Methods  \n",
    "\n",
    "Dear professor Michel Toulouse!  \n",
    "\n",
    "I am writing to present the progress of my work on the Retrieval-Augmented Generation (RAG) strategy and my research into chunking and indexing methods.\n",
    "\n",
    "1. Summary of RAG Research Direction  \n",
    "    This report outlines the progress of my research on RAG.\n",
    "I am currently exploring various methods to enhance the efficiency and effectiveness of the retrieval-augmented generation process.  \n",
    "Thank you, professor, for taking the time to review my work and provide valuable insights.  \n",
    "\n",
    "2. Research on Chunking Strategies  \n",
    "    I have analyzed several chunking strategies to evaluate their applicability to our current dataset. Below is a summarized evaluation:  \n",
    "- Hybrid Chunking: Combines fixed-size and sentence-based methods for optimal context retention.  \n",
    "- Semantic Chunking: Utilizes language models for meaning-preserving chunking.  \n",
    "- Hybrid-Semantic Chunking: A combination of fixed-size and semantic chunking. In theory, this approach should outperform the first two methods. I plan to implement this strategy on a real dataset to evaluate its effectiveness.  \n",
    "- RAPTOR RAG: A chunking strategy that incorporates clustering and summary-based grouping. I am currently researching this approach with reference to the implementation here: [RAPTOR GitHub Repository](https://github.com/parthsarthi03/raptor) and the accompanying paper: [arXiv:2401.18059](https://arxiv.org/abs/2401.18059).  \n",
    "- Future Exploration: I aim to investigate additional chunking strategies and would highly value your suggestions on modern and effective chunking methods.  \n",
    "\n",
    " 3. Research on Indexing: HNSW  \n",
    "    I am focusing on the HNSW (Hierarchical Navigable Small World) method for indexing.  \n",
    "However, there may be other indexing methods that are more suitable for RAG tasks. I would greatly appreciate your recommendations on alternative indexing techniques that could enhance the performance of RAG systems.  \n",
    "\n",
    "My research capabilities are still limited, and I would greatly appreciate your feedback and recommendations to help me improve my research and refine my approach further!\n",
    "\n",
    "Thank professor for your time and support!\n",
    "Best regards,  \n",
    "Doan Ngoc Cuong\n",
    "cuong.dn210141@sis.hust.edu.vn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
